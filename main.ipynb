{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84e418d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.core.loader import load_dataset, preview_dataset , DataLoader, DatasetInfo\n",
    "import polars as pl\n",
    "csv_data = \"data/examples/customers-2000000.csv\"\n",
    "json_data = \"data/examples/flights-1m.json\"\n",
    "df = load_dataset(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95f9ee3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>FL_DATE</th><th>DEP_DELAY</th><th>ARR_DELAY</th><th>AIR_TIME</th><th>DISTANCE</th><th>DEP_TIME</th><th>ARR_TIME</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;2006-01-01&quot;</td><td>5</td><td>19</td><td>350</td><td>2475</td><td>9.083333</td><td>12.483334</td></tr><tr><td>&quot;2006-01-02&quot;</td><td>167</td><td>216</td><td>343</td><td>2475</td><td>11.783334</td><td>15.766666</td></tr><tr><td>&quot;2006-01-03&quot;</td><td>-7</td><td>-2</td><td>344</td><td>2475</td><td>8.883333</td><td>12.133333</td></tr><tr><td>&quot;2006-01-04&quot;</td><td>-5</td><td>-13</td><td>331</td><td>2475</td><td>8.916667</td><td>11.95</td></tr><tr><td>&quot;2006-01-05&quot;</td><td>-3</td><td>-17</td><td>321</td><td>2475</td><td>8.95</td><td>11.883333</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌────────────┬───────────┬───────────┬──────────┬──────────┬───────────┬───────────┐\n",
       "│ FL_DATE    ┆ DEP_DELAY ┆ ARR_DELAY ┆ AIR_TIME ┆ DISTANCE ┆ DEP_TIME  ┆ ARR_TIME  │\n",
       "│ ---        ┆ ---       ┆ ---       ┆ ---      ┆ ---      ┆ ---       ┆ ---       │\n",
       "│ str        ┆ i64       ┆ i64       ┆ i64      ┆ i64      ┆ f64       ┆ f64       │\n",
       "╞════════════╪═══════════╪═══════════╪══════════╪══════════╪═══════════╪═══════════╡\n",
       "│ 2006-01-01 ┆ 5         ┆ 19        ┆ 350      ┆ 2475     ┆ 9.083333  ┆ 12.483334 │\n",
       "│ 2006-01-02 ┆ 167       ┆ 216       ┆ 343      ┆ 2475     ┆ 11.783334 ┆ 15.766666 │\n",
       "│ 2006-01-03 ┆ -7        ┆ -2        ┆ 344      ┆ 2475     ┆ 8.883333  ┆ 12.133333 │\n",
       "│ 2006-01-04 ┆ -5        ┆ -13       ┆ 331      ┆ 2475     ┆ 8.916667  ┆ 11.95     │\n",
       "│ 2006-01-05 ┆ -3        ┆ -17       ┆ 321      ┆ 2475     ┆ 8.95      ┆ 11.883333 │\n",
       "└────────────┴───────────┴───────────┴──────────┴──────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cdca8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: 12\n",
      "shape: (5, 12)\n",
      "┌───────┬────────────┬────────────┬───────────┬───┬────────────┬───────────┬───────────┬───────────┐\n",
      "│ Index ┆ Customer   ┆ First Name ┆ Last Name ┆ … ┆ Phone 2    ┆ Email     ┆ Subscript ┆ Website   │\n",
      "│ ---   ┆ Id         ┆ ---        ┆ ---       ┆   ┆ ---        ┆ ---       ┆ ion Date  ┆ ---       │\n",
      "│ i64   ┆ ---        ┆ str        ┆ str       ┆   ┆ str        ┆ str       ┆ ---       ┆ str       │\n",
      "│       ┆ str        ┆            ┆           ┆   ┆            ┆           ┆ str       ┆           │\n",
      "╞═══════╪════════════╪════════════╪═══════════╪═══╪════════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ 1     ┆ 4962fdbE6B ┆ Pam        ┆ Sparks    ┆ … ┆ 480-078-05 ┆ nicolas00 ┆ 2020-11-2 ┆ https://n │\n",
      "│       ┆ fee6D      ┆            ┆           ┆   ┆ 35x889     ┆ @faulkner ┆ 9         ┆ elson.com │\n",
      "│       ┆            ┆            ┆           ┆   ┆            ┆ -kramer.c ┆           ┆ /         │\n",
      "│       ┆            ┆            ┆           ┆   ┆            ┆ om        ┆           ┆           │\n",
      "│ 2     ┆ 9b12Ae76fd ┆ Gina       ┆ Rocha     ┆ … ┆ +1-752-593 ┆ yfarley@m ┆ 2021-01-0 ┆ https://p │\n",
      "│       ┆ Bc9bE      ┆            ┆           ┆   ┆ -4777x0717 ┆ organ.com ┆ 3         ┆ ineda-rog │\n",
      "│       ┆            ┆            ┆           ┆   ┆ 1          ┆           ┆           ┆ ers.biz/  │\n",
      "│ 3     ┆ 39edFd2F60 ┆ Kristie    ┆ Greer     ┆ … ┆ +1-311-216 ┆ jennyhayd ┆ 2021-06-2 ┆ https://m │\n",
      "│       ┆ C85BC      ┆            ┆           ┆   ┆ -7855      ┆ en@petty. ┆ 0         ┆ ckinney.c │\n",
      "│       ┆            ┆            ┆           ┆   ┆            ┆ org       ┆           ┆ om/       │\n",
      "│ 4     ┆ Fa42AE6a9a ┆ Arthur     ┆ Fields    ┆ … ┆ 521-630-38 ┆ igrimes@r ┆ 2020-02-1 ┆ https://d │\n",
      "│       ┆ D39cE      ┆            ┆           ┆   ┆ 58x953     ┆ uiz-todd. ┆ 3         ┆ ominguez. │\n",
      "│       ┆            ┆            ┆           ┆   ┆            ┆ org       ┆           ┆ biz/      │\n",
      "│ 5     ┆ F5702Edae9 ┆ Michelle   ┆ Blevins   ┆ … ┆ (633)283-6 ┆ diamondca ┆ 2020-10-2 ┆ http://mu │\n",
      "│       ┆ 25F1D      ┆            ┆           ┆   ┆ 034x500    ┆ rter@jord ┆ 0         ┆ rillo-rya │\n",
      "│       ┆            ┆            ┆           ┆   ┆            ┆ an.com    ┆           ┆ n.com/    │\n",
      "└───────┴────────────┴────────────┴───────────┴───┴────────────┴───────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "preview = preview_dataset(csv_data, n_rows=5)\n",
    "print(f\"Columns: {preview['columns']}\")\n",
    "print(preview['preview'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff2d65f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 7)\n",
      "┌────────────┬───────────┬───────────┬──────────┬──────────┬───────────┬───────────┐\n",
      "│ FL_DATE    ┆ DEP_DELAY ┆ ARR_DELAY ┆ AIR_TIME ┆ DISTANCE ┆ DEP_TIME  ┆ ARR_TIME  │\n",
      "│ ---        ┆ ---       ┆ ---       ┆ ---      ┆ ---      ┆ ---       ┆ ---       │\n",
      "│ str        ┆ i64       ┆ i64       ┆ i64      ┆ i64      ┆ f64       ┆ f64       │\n",
      "╞════════════╪═══════════╪═══════════╪══════════╪══════════╪═══════════╪═══════════╡\n",
      "│ 2006-01-01 ┆ 5         ┆ 19        ┆ 350      ┆ 2475     ┆ 9.083333  ┆ 12.483334 │\n",
      "│ 2006-01-02 ┆ 167       ┆ 216       ┆ 343      ┆ 2475     ┆ 11.783334 ┆ 15.766666 │\n",
      "│ 2006-01-03 ┆ -7        ┆ -2        ┆ 344      ┆ 2475     ┆ 8.883333  ┆ 12.133333 │\n",
      "│ 2006-01-04 ┆ -5        ┆ -13       ┆ 331      ┆ 2475     ┆ 8.916667  ┆ 11.95     │\n",
      "│ 2006-01-05 ┆ -3        ┆ -17       ┆ 321      ┆ 2475     ┆ 8.95      ┆ 11.883333 │\n",
      "└────────────┴───────────┴───────────┴──────────┴──────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(lazy=True)\n",
    "lazy_df = loader.load(json_data)\n",
    "print(lazy_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "962818b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2,000,000 rows in 1.41s\n",
      "Encoding: utf-8\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(lazy=False)\n",
    "lazy_df = loader.load(csv_data)\n",
    "info = loader.get_info()\n",
    "print(f\"Loaded {info.rows:,} rows in {info.load_time_seconds:.2f}s\")\n",
    "print(f\"Encoding: {info.encoding}\")\n",
    "if info.warnings:\n",
    "    print(\"Warnings:\", info.warnings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38e5f644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: numeric (none)\n",
      "Customer Id: text (none)\n",
      "First Name: categorical (none)\n",
      "Last Name: categorical (none)\n",
      "Company: text (none)\n",
      "City: text (none)\n",
      "Country: categorical (none)\n",
      "Phone 1: text (phone)\n",
      "Phone 2: text (phone)\n",
      "Email: text (email)\n",
      "Subscription Date: datetime (none)\n",
      "Website: text (url)\n"
     ]
    }
   ],
   "source": [
    "from src.core.schema import detect_schema, get_schema_summary\n",
    "\n",
    "\n",
    "df = load_dataset(csv_data)\n",
    "\n",
    "schema = detect_schema(df)\n",
    "for col_name, col_info in schema.items():\n",
    "    print(f\"{col_name}: {col_info.data_type.value} ({col_info.semantic_type.value})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d12354b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns: 12\n",
      "Memory usage: 298.69 MB\n",
      "Type distribution: {'numeric': 1, 'text': 7, 'categorical': 3, 'datetime': 1}\n"
     ]
    }
   ],
   "source": [
    "summary = get_schema_summary(df)\n",
    "print(f\"Total columns: {summary['total_columns']}\")\n",
    "print(f\"Memory usage: {summary['total_memory_mb']:.2f} MB\")\n",
    "print(f\"Type distribution: {summary['type_distribution']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8da658e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.core.statistics import (\n",
    "    analyze_statistics, \n",
    "    get_statistics_summary,\n",
    "    NumericStats,\n",
    "    CategoricalStats,\n",
    "    DatetimeStats,\n",
    "    TextStats\n",
    ")\n",
    "\n",
    "stats = analyze_statistics(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5804509c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 1000000.5\n",
      "Std: 577350.4135271751\n",
      "Skewness: 1.8427188811611887e-16\n"
     ]
    }
   ],
   "source": [
    "if isinstance(stats['Index'], NumericStats):\n",
    "    print(f\"Mean: {stats['Index'].mean}\")\n",
    "    print(f\"Std: {stats['Index'].std}\")\n",
    "    print(f\"Skewness: {stats['Index'].skewness}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a9103e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: Korea\n",
      "Unique: 243\n",
      "Top values: [('Korea', 16240, 0.812), ('Congo', 16208, 0.8104), ('Jordan', 8428, 0.4214)]\n"
     ]
    }
   ],
   "source": [
    "if isinstance(stats['Country'], CategoricalStats):\n",
    "    print(f\"Mode: {stats['Country'].mode}\")\n",
    "    print(f\"Unique: {stats['Country'].unique_count}\")\n",
    "    print(\"Top values:\", stats['Country'].top_values[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6bed8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: ['Index']\n",
      "Categorical columns: ['First Name', 'Last Name', 'Country']\n"
     ]
    }
   ],
   "source": [
    "summary = get_statistics_summary(df)\n",
    "print(f\"Numeric columns: {summary['numeric_columns']}\")\n",
    "print(f\"Categorical columns: {summary['categorical_columns']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af152767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.core.missing import (\n",
    "    analyze_missing,\n",
    "    get_missing_summary,\n",
    "    get_missing_heatmap_data,\n",
    "    detect_missing_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e79bf35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing: 0\n",
      "Overall missing %: 0.00%\n",
      "Complete rows: 1000000 (100.00%)\n",
      "\n",
      "Top missing patterns:\n",
      "\n",
      "High missing columns: []\n",
      "Medium missing columns: []\n",
      "\n",
      "Heatmap matrix shape: 100 x 7\n",
      "Email missing type: unknown\n"
     ]
    }
   ],
   "source": [
    "# Full analysis\n",
    "missing_analysis = analyze_missing(df)\n",
    "print(f\"Total missing: {missing_analysis['total_missing_values']}\")\n",
    "print(f\"Overall missing %: {missing_analysis['overall_missing_percentage']:.2f}%\")\n",
    "print(f\"Complete rows: {missing_analysis['complete_rows']} ({missing_analysis['complete_rows_percentage']:.2f}%)\")\n",
    "\n",
    "# Per column\n",
    "for col, info in missing_analysis['columns'].items():\n",
    "    if info.missing_count > 0:\n",
    "        print(f\"{col}: {info.missing_count} missing ({info.missing_percentage:.2f}%)\")\n",
    "\n",
    "# Patterns\n",
    "print(\"\\nTop missing patterns:\")\n",
    "for pattern in missing_analysis['patterns'][:3]:\n",
    "    print(f\"  {pattern.columns}: {pattern.count} rows ({pattern.percentage:.2f}%)\")\n",
    "\n",
    "# Summary\n",
    "summary = get_missing_summary(df)\n",
    "print(f\"\\nHigh missing columns: {summary['high_missing_columns']}\")\n",
    "print(f\"Medium missing columns: {summary['medium_missing_columns']}\")\n",
    "\n",
    "# Heatmap data for visualization\n",
    "heatmap = get_missing_heatmap_data(df, sample_size=100)\n",
    "print(f\"\\nHeatmap matrix shape: {len(heatmap['matrix'])} x {len(heatmap['columns'])}\")\n",
    "\n",
    "# Detect missing type\n",
    "missing_type = detect_missing_type(df, 'Email')\n",
    "print(f\"Email missing type: {missing_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6aa6911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.core.outliers import (\n",
    "    detect_outliers,\n",
    "    detect_multivariate_outliers,\n",
    "    get_outlier_summary,\n",
    "    get_outliers_for_column\n",
    ")\n",
    "\n",
    "df = load_dataset(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1dacd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEP_DELAY:\n",
      "  IQR outliers: 120804 (12.38%)\n",
      "  Bounds: [-22.00, 26.00]\n",
      "ARR_DELAY:\n",
      "  IQR outliers: 84250 (8.43%)\n",
      "  Bounds: [-41.50, 42.50]\n",
      "AIR_TIME:\n",
      "  IQR outliers: 45857 (4.59%)\n",
      "  Bounds: [-66.50, 257.50]\n",
      "DISTANCE:\n",
      "  IQR outliers: 49707 (4.97%)\n",
      "  Bounds: [-663.50, 1972.50]\n"
     ]
    }
   ],
   "source": [
    "outliers = detect_outliers(df)\n",
    "for col, info in outliers.items():\n",
    "    if info.iqr_outlier_count > 0:\n",
    "        print(f\"{col}:\")\n",
    "        print(f\"  IQR outliers: {info.iqr_outlier_count} ({info.outlier_percentage:.2f}%)\")\n",
    "        print(f\"  Bounds: [{info.iqr_lower_bound:.2f}, {info.iqr_upper_bound:.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77c25eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns with outliers: ['DEP_DELAY', 'ARR_DELAY', 'AIR_TIME', 'DISTANCE', 'ARR_TIME']\n",
      "High outlier columns: [('DEP_DELAY', 12.380099999999999), ('ARR_DELAY', 8.425)]\n",
      "\n",
      "DEP_DELAY outliers (IQR): 120804\n",
      "DEP_DELAY outliers (Z-score): 20987\n",
      "DEP_DELAY outliers (MAD): 123700\n",
      "\n",
      "Multivariate outliers: 50000 (5.00%)\n",
      "First 10 outlier rows: [0, 1, 5, 12, 22, 23, 24, 28, 35, 39]\n"
     ]
    }
   ],
   "source": [
    "summary = get_outlier_summary(df)\n",
    "print(f\"\\nColumns with outliers: {summary['columns_with_outliers']}\")\n",
    "print(f\"High outlier columns: {summary['high_outlier_columns']}\")\n",
    "\n",
    "# Specific column (use actual column from your data)\n",
    "col_outliers = get_outliers_for_column(df, 'DEP_DELAY')\n",
    "print(f\"\\nDEP_DELAY outliers (IQR): {col_outliers['iqr']['count']}\")\n",
    "print(f\"DEP_DELAY outliers (Z-score): {col_outliers['zscore']['count']}\")\n",
    "print(f\"DEP_DELAY outliers (MAD): {col_outliers['mad']['count']}\")\n",
    "\n",
    "# Multivariate outliers (multiple columns together)\n",
    "multi_outliers = detect_multivariate_outliers(\n",
    "    df, \n",
    "    columns=['DEP_DELAY', 'ARR_DELAY', 'AIR_TIME'], \n",
    "    contamination=0.05\n",
    ")\n",
    "print(f\"\\nMultivariate outliers: {multi_outliers.outlier_count} ({multi_outliers.outlier_percentage:.2f}%)\")\n",
    "print(f\"First 10 outlier rows: {multi_outliers.outlier_indices[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f99dcf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.core.correlations import (\n",
    "    analyze_correlations,\n",
    "    get_correlation_matrix,\n",
    "    get_top_correlations,\n",
    "    get_correlation_for_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42723ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: ['DEP_DELAY', 'ARR_DELAY', 'AIR_TIME', 'DISTANCE', 'DEP_TIME', 'ARR_TIME']\n",
      "Categorical columns: ['FL_DATE']\n"
     ]
    }
   ],
   "source": [
    "correlations = analyze_correlations(df)\n",
    "print(f\"Numeric columns: {correlations['numeric_columns']}\")\n",
    "print(f\"Categorical columns: {correlations['categorical_columns']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f161feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 correlations:\n",
      "  AIR_TIME ↔ DISTANCE: 0.978 (spearman)\n",
      "  AIR_TIME ↔ DISTANCE: 0.976 (pearson)\n",
      "  DEP_DELAY ↔ ARR_DELAY: 0.905 (pearson)\n",
      "  DEP_TIME ↔ ARR_TIME: 0.822 (spearman)\n",
      "  DEP_TIME ↔ ARR_TIME: 0.723 (pearson)\n",
      "  DEP_DELAY ↔ ARR_DELAY: 0.640 (spearman)\n",
      "\n",
      "Correlation matrix shape: 6 x 6\n",
      "\n",
      "DEP_DELAY vs ARR_DELAY:\n",
      "  Pearson: 0.905\n",
      "  Spearman: 0.640\n"
     ]
    }
   ],
   "source": [
    "# Top correlations\n",
    "top_corr = get_top_correlations(df, n=10, min_correlation=0.5)\n",
    "print(\"\\nTop 10 correlations:\")\n",
    "for pair in top_corr:\n",
    "    print(f\"  {pair.column1} ↔ {pair.column2}: {pair.correlation:.3f} ({pair.method})\")\n",
    "\n",
    "# Correlation matrix (for heatmap)\n",
    "matrix = get_correlation_matrix(df, method='pearson')\n",
    "print(f\"\\nCorrelation matrix shape: {len(matrix['columns'])} x {len(matrix['columns'])}\")\n",
    "\n",
    "# Specific pair\n",
    "pair_corr = get_correlation_for_columns(df, 'DEP_DELAY', 'ARR_DELAY')\n",
    "print(f\"\\nDEP_DELAY vs ARR_DELAY:\")\n",
    "print(f\"  Pearson: {pair_corr['pearson']['correlation']:.3f}\")\n",
    "print(f\"  Spearman: {pair_corr['spearman']['correlation']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c3acb7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.core.distributions import (\n",
    "    analyze_distributions,\n",
    "    get_distribution_summary,\n",
    "    get_histogram,\n",
    "    get_kde,\n",
    "    test_normality\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "187c6223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DEP_DELAY:\n",
      "  Distribution type: right_skewed\n",
      "  Is normal: False\n",
      "  Skewness: 5.693\n",
      "  Kurtosis: 110.204\n",
      "\n",
      "ARR_DELAY:\n",
      "  Distribution type: right_skewed\n",
      "  Is normal: False\n",
      "  Skewness: 5.295\n",
      "  Kurtosis: 68.233\n",
      "\n",
      "AIR_TIME:\n",
      "  Distribution type: right_skewed\n",
      "  Is normal: False\n",
      "  Skewness: 1.580\n",
      "  Kurtosis: 3.245\n",
      "\n",
      "DISTANCE:\n",
      "  Distribution type: right_skewed\n",
      "  Is normal: False\n",
      "  Skewness: 1.627\n",
      "  Kurtosis: 3.460\n",
      "\n",
      "DEP_TIME:\n",
      "  Distribution type: unknown\n",
      "  Is normal: False\n",
      "  Skewness: 0.023\n",
      "  Kurtosis: -0.963\n",
      "\n",
      "ARR_TIME:\n",
      "  Distribution type: approximately_normal\n",
      "  Is normal: False\n",
      "  Skewness: -0.332\n",
      "  Kurtosis: -0.363\n"
     ]
    }
   ],
   "source": [
    "distributions = analyze_distributions(df, bins=50)\n",
    "for col, info in distributions.items():\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Distribution type: {info.distribution_type}\")\n",
    "    print(f\"  Is normal: {info.is_normal}\")\n",
    "    print(f\"  Skewness: {info.skewness:.3f}\")\n",
    "    print(f\"  Kurtosis: {info.kurtosis:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f76664e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normal columns: []\n",
      "Skewed columns: ['DEP_DELAY', 'ARR_DELAY', 'AIR_TIME', 'DISTANCE']\n",
      "Distribution types: {'right_skewed': 4, 'unknown': 1, 'approximately_normal': 1}\n",
      "\n",
      "DEP_DELAY histogram:\n",
      "  Bins: 30\n",
      "  Total count: 1000000\n",
      "  KDE computed with 100 points\n",
      "\n",
      "ARR_DELAY normality tests:\n",
      "  Anderson-Darling: stat=84750.5748\n",
      "  Overall normal: False\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "summary = get_distribution_summary(df)\n",
    "print(f\"\\nNormal columns: {summary['normal_columns']}\")\n",
    "print(f\"Skewed columns: {summary['skewed_columns']}\")\n",
    "print(f\"Distribution types: {summary['distribution_type_counts']}\")\n",
    "\n",
    "# Histogram for specific column\n",
    "hist = get_histogram(df, 'DEP_DELAY', bins=30)\n",
    "print(f\"\\nDEP_DELAY histogram:\")\n",
    "print(f\"  Bins: {len(hist['counts'])}\")\n",
    "print(f\"  Total count: {hist['total_count']}\")\n",
    "\n",
    "# KDE for smooth density plot\n",
    "kde = get_kde(df, 'DEP_DELAY', num_points=100)\n",
    "if kde:\n",
    "    print(f\"  KDE computed with {len(kde['x'])} points\")\n",
    "\n",
    "# Normality tests\n",
    "normality = test_normality(df, 'ARR_DELAY')\n",
    "print(f\"\\nARR_DELAY normality tests:\")\n",
    "if normality.get('shapiro_wilk'):\n",
    "    print(f\"  Shapiro-Wilk: p={normality['shapiro_wilk']['p_value']:.4f}\")\n",
    "if normality.get('anderson_darling'):\n",
    "    print(f\"  Anderson-Darling: stat={normality['anderson_darling']['statistic']:.4f}\")\n",
    "print(f\"  Overall normal: {normality['is_normal']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231b239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.analyzer import DataAnalyzer, analyze_dataset, quick_analyze, get_data_quality_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datatui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
